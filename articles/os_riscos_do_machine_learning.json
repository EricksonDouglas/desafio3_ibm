{"author": "Reda\u00e7\u00e3o Olhar Digital", "body": "A intelig&ecirc;ncia artificial, e consequentemente o machine learning, vem sendo objeto de estudo desde a d&eacute;cada de 1940, quando surgiram os primeiros neur&ocirc;nios artificiais. Desde ent&atilde;o, os desenvolvedores de c&oacute;digos computacionais v&ecirc;m aprimorando suas t&eacute;cnicas com o objetivo de simular a intelig&ecirc;ncia humana e a nossa forma de adquirir conhecimento.Sabemos que a maioria de nossas habilidades s&atilde;o aprendidas ao longo da inf&acirc;ncia e da juventude at&eacute; a vida adulta como por exemplo: falar, andar, escrever, dirigir autom&oacute;veis, praticar esportes, entre outros. Aprendemos olhando, escutando, interagindo e praticando algo que nos interessa ou que nos &eacute; apresentado como necessidade ou como fonte de prazer. Nos algoritmos computacionais, o conceito atual de aprendizado de m&aacute;quina &eacute; semelhante: treinamos as intelig&ecirc;ncias artificiais sempre que interagimos com uma. As redes neurais artificiais s&atilde;o desenvolvidas para se comportar como uma esponja de absor&ccedil;&atilde;o de conhecimento, tal qual os beb&ecirc;s quando est&atilde;o se desenvolvendo, todos sedentos por conhecimentos.Outra forma de ensinarmos uma m&aacute;quina &eacute; apresentando a ela grandes quantidades de informa&ccedil;&otilde;es em forma de solu&ccedil;&otilde;es desenvolvidas por seres humanos. Desta forma, as redes neurais artificiais aprendem como resolvemos problemas e passam a seguir os nossos padr&otilde;es e, posteriormente, podem adotar seus pr&oacute;prios.&nbsp; Um exemplo interessante deste tipo de aprendizado &eacute; a experi&ecirc;ncia da IBM com o Watson. Ele foi ensinado a criar trailer de filmes atrav&eacute;s da compara&ccedil;&atilde;o entre as produ&ccedil;&otilde;es cinematogr&aacute;ficas e seus respectivos trailers. Watson &ldquo;entendeu&rdquo; como os seres humanos os criam: qual o padr&atilde;o que os cortes devem seguir de acordo com as express&otilde;es faciais dos atores, qual o volume da trilha sonora, quanto tempo deve ter, entre outras caracter&iacute;sticas.Neste contexto, &eacute; importante ressaltar a import&acirc;ncia da qualidade das informa&ccedil;&otilde;es apresentadas &agrave;s intelig&ecirc;ncias artificiais e, principalmente, a idoneidade das pessoas que est&atilde;o treinando as redes neurais artificiais, pois corre-se o risco de se desenvolver intelig&ecirc;ncias artificiais preconceituosas, com tend&ecirc;ncias mal&eacute;ficas. O chatbot Tay, da Microsoft, &eacute; um exemplo de como pessoas mal-intencionadas podem ensinar coisas ruins para uma intelig&ecirc;ncia artificial. Tay foi desenvolvido para interagir e aprender com jovens entre 18 e 24 anos. Por&eacute;m, alguns delinquentes bombardearam o chatbot com mensagens em prol do nazismo. Com isso, Tay come&ccedil;ou tuitar espontaneamente mensagens e imagens a favor de Hitler, como o exemplo a seguir:&nbsp;&nbsp;Outro exemplo mais recente foi o desafio aceito por um time do laborat&oacute;rio de m&iacute;dia do MIT - Instituto de Tecnologia de Massachusetts. Tr&ecirc;s pesquisadores desenvolveram uma intelig&ecirc;ncia artificial psicopata, deram a ela o nome de Norman, em homenagem a Norman Bates, personagem do filme Psicose de 1960. Para tanto, foram programadas duas redes neurais com o objetivo de interpretar imagens. Para o treinamento destas duas redes foram usadas imagens com dois padr&otilde;es diferentes. Para a rede Norman, apresentou-se imagens violentas de cenas de mortes e para a outra rede, foram utilizadas imagens comuns da internet.O resultado n&atilde;o podia ser diferente. Norman aprendeu a ter comportamento de um psicopata na interpreta&ccedil;&atilde;o de imagens e a outra rede teve uma atua&ccedil;&atilde;o bem mais amena. Para comprovar o experimento, os pesquisadores utilizaram o teste de Rorschach, usado por psic&oacute;logos para a avalia&ccedil;&atilde;o da sa&uacute;de mental e emocional dos pacientes. Foram apresentados os borr&otilde;es de Rorschach &agrave;s duas redes neurais e o resultado foi surpreendente. Enquanto a rede neural normal interpretava as figuras como sendo p&aacute;ssaros inofensivos, Norman interpretava as mesmas imagens como sendo pessoas mortas de forma violenta. (Este experimento pode ser acessado na &iacute;ntegra em http://norman-ai.mit.edu/)Estes dois exemplos ilustram a import&acirc;ncia de estarmos atentos ao treinamento das intelig&ecirc;ncias artificiais que est&atilde;o presentes em nosso dia a dia: nos atendimentos em hospitais, na &aacute;rea da seguran&ccedil;a, na educa&ccedil;&atilde;o, em finan&ccedil;as, em entretenimento etc. Dependendo das informa&ccedil;&otilde;es expostas e das pessoas envolvidas na transmiss&atilde;o de conhecimentos para as redes neurais artificiais, podemos ter surpresas desagrad&aacute;veis em um futuro muito pr&oacute;ximo.&nbsp;", "title": "Os riscos do Machine Learning", "type": "Article", "url": "https://olhardigital.com.br/colunistas/wagner_sanchez/post/os_riscos_do_machine_learning/80584"}